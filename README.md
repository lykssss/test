# CV 寒假第一轮考核

##  吴恩达深度学习篇

### 1.1 简述过拟合和欠拟合的原因
#### 欠拟合：数据较为复杂，同时模型的性能较差，拟合非线性的能力不强
#### 过拟合：训练数据不够，或者模型性能过强，在后期学习仅在训练数据中才有的特征，从而使泛化能力变弱
---

### 1.2 简述正则化的原理
#### 通过对权重进行惩罚从而降低权重的大小，其实就是变相减小权重的影响，减弱模型的非线性能力
---

### 1.3 简述梯度下降的原理
#### 通过求代价偏导的方法来获得方向，然后来跟更参数
---

### 1.4 简述梯度下降的优化方法
#### 动量法，RMSProp，ADAM
---

### 1.5 简述常用的激活函数
#### Sigmoid，Tanh，ReLU，Leaky ReLU，Softmax
---

### 1.6 简述神经网络的前向传播和反向传播
#### 前向传播：前向传播就是从输入层开始，经过一层层的网络，不断计算每一层的神经网络得到的结果及通过激活函数的本层输出结果，最后得到输出的过程。

#### 反向传播：使用链式求导法则，从输出层开始，将每一次的梯度从后往前传递，最后求出总梯度，从而能够使用梯度下降算法
---

### 1.7 简述常用的预防过拟合的方法
#### 数据增强，Dropout，正则化
---

### 1.8 简述使用全连接层结构处理图像时会出现什么问题
#### 丢失空间信息，产生大量的参数，计算量庞大
---
### 1.9 简述卷积的类型，什么是卷积感受野
#### 类型：标准卷积，空间卷积，可分离卷积，转置卷积
#### 感受野：卷积神经网络每一层输出的特征图上的像素点在输入图片上映射的区域大小
---

## CS231n篇
### 2.1 简述卷积神经网络的原理 
#### 通过学习后提取图像中的一些纹理基元如线条，圆点等基本特征，然后随着卷积网络层数的加深将这些特征提取成一些高级复杂的特征，在通过全连接层来分类
---
### 2.2 简述卷积神经网络的优化方法
#### dropout 和 级联卷积核
---
### 2.3 简述卷积神经网络的常用层
#### 输入层，卷积层，池化层，全连接层，输出层
---
### 2.4 简述卷积神经网络的常用结构
#### 输入层，卷积层，池化层，全连接层，输出层
---

# test
